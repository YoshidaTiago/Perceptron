# Perceptron

### Inicialização

Os pesos $w_1, w_2,..., w_n$ e o bias $b$ são iniciados com zeros

### Processo

1. Com a entrada $x = (x_1, x_2, ..., x_n)$ e uma saída espera $y$ (sendo 0 ou 1)
2. Calcula a saída do perceptron:
    
    $$
    z = x_1 * w_1 + x_2 * w_2 + ... + x_n * w_n + b
    $$
    
3. Aplica a função de ativação:
    
    $$
    saída = \begin{cases}
    1 & \text{ se } z \geq 0 \\
    0 & \text{ se } z < 0
    \end{cases}
    $$
    
4. Com para a saída espera:
Se a saída gerada for diferente da esperada, o perceptron atualiza os pesos.

### Atualização dos pesos

$$
w_i = w_i + \alpha * (y - \hat{y})
$$

$$
b = b + \alpha * (y - \hat{y})
$$

- $y$ = saída espera
- $\hat{y}$ = saída do perceptron
- $\alpha$ = taxa de aprendizado, evita que a correção seja brusca demais
- $x_i$ = valor de entrada, indica quais dimensões do espaço precisam de mais correção

### Repetição

Esse processo é repetido para vários ciclos (épocas), até o perceptron acertar todos os exemplos (ou atingir um número máximo de ciclos).
